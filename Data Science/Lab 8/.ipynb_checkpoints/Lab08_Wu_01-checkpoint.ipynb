{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.7196495860528949\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def compute_mae_using_pearson(user_ratings_train, user_ratings_test):\n",
    "    # 1. Deal with NaN values in training data\n",
    "    user_ratings_train_noNan = user_ratings_train.fillna(0)\n",
    "\n",
    "    # Compute Pearson correlation between all pairs of users in the training set\n",
    "    pearson_sim_train = 1 - pairwise_distances(user_ratings_train_noNan, metric=\"correlation\")\n",
    "\n",
    "    # Train a k-nearest neighbors model on the Pearson similarity matrix\n",
    "    train_model = NearestNeighbors(n_neighbors=5)\n",
    "    train_model.fit(pearson_sim_train)\n",
    "\n",
    "    # Get distances and indices of the 5 nearest neighbors for each user\n",
    "    neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "    neighbors_ind += 1\n",
    "\n",
    "    predictions = []\n",
    "    actual = []\n",
    "\n",
    "    # 3. For each entry in the testing data with values, find neighbors in training with Pearson correlation\n",
    "    for user_id, row in user_ratings_test.iterrows():\n",
    "        for movie, rating in row.iteritems():\n",
    "            # 2. Only need to predict ratings for entries in testing data with values (NOT NaN)\n",
    "            if not pd.isnull(rating):\n",
    "                predicted_rating = 0\n",
    "                sum_of_sim = 0\n",
    "\n",
    "                # 4. Use the formula from slides to make predictions\n",
    "                for x in range(0, 5):\n",
    "                    neigh_id = neighbors_ind[user_id - 1][x]\n",
    "                    neigh_rating = user_ratings_train.loc[neigh_id, movie]\n",
    "                    if not pd.isnull(neigh_rating):\n",
    "                        neigh_distance = neighbors_distance[user_id - 1][x]\n",
    "                        sum_of_sim += neigh_distance\n",
    "                        predicted_rating += neigh_distance * neigh_rating\n",
    "\n",
    "                # Normalize the predicted rating\n",
    "                if sum_of_sim != 0:\n",
    "                    predicted_rating = predicted_rating / sum_of_sim\n",
    "\n",
    "                # 5. Save the original ground truth ratings in the testing data\n",
    "                actual.append(rating)\n",
    "                # 6. Save the predictions\n",
    "                predictions.append(predicted_rating)\n",
    "\n",
    "    # 7. Apply MAE function on these two lists\n",
    "    mae = mean_absolute_error(predictions, actual)\n",
    "    return mae\n",
    "\n",
    "# Test the function with your user_ratings_train and user_ratings_test dataframes\n",
    "mae = compute_mae_using_pearson(user_ratings_train, user_ratings_test)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.595714302471743\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def compute_mae_using_cosine(user_ratings_train, user_ratings_test):\n",
    "    # 1. Deal with NaN values in training data\n",
    "    user_ratings_train_noNan = user_ratings_train.fillna(0)\n",
    "\n",
    "    # Compute cosine similarity between all pairs of items in the training set\n",
    "    cosine_sim_train = 1 - pairwise_distances(user_ratings_train_noNan.T, metric=\"cosine\")\n",
    "\n",
    "    # Train a k-nearest neighbors model on the cosine similarity matrix\n",
    "    train_model = NearestNeighbors(n_neighbors=5)\n",
    "    train_model.fit(cosine_sim_train)\n",
    "\n",
    "    # Get distances and indices of the 5 nearest neighbors for each item\n",
    "    neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "\n",
    "    predictions = []\n",
    "    actual = []\n",
    "\n",
    "    # 3. For each entry in the testing data with values, find items in training with cosine correlation\n",
    "    for user_id, row in user_ratings_test.iterrows():\n",
    "        for movie, rating in row.iteritems():\n",
    "            # 2. Only need to predict ratings for entries in testing data with values (NOT NaN)\n",
    "            if not pd.isnull(rating):\n",
    "                predicted_rating = 0\n",
    "                sum_of_sim = 0\n",
    "                \n",
    "                # Get the index of the movie in the training data\n",
    "                movie_index = user_ratings_train.columns.get_loc(movie)\n",
    "\n",
    "                # 4. Use the formula from slides to make predictions\n",
    "                for x in range(0, 5):\n",
    "                    neigh_id = neighbors_ind[movie_index][x]\n",
    "                    neigh_rating = user_ratings_train.iloc[user_id - 1, neigh_id]\n",
    "                    if not pd.isnull(neigh_rating):\n",
    "                        neigh_distance = neighbors_distance[movie_index][x]\n",
    "                        sum_of_sim += neigh_distance\n",
    "                        predicted_rating += neigh_distance * neigh_rating\n",
    "\n",
    "                # Normalize the predicted rating\n",
    "                if sum_of_sim != 0:\n",
    "                    predicted_rating = predicted_rating / sum_of_sim\n",
    "\n",
    "                # 5. Save the original ground truth ratings in the testing data\n",
    "                actual.append(rating)\n",
    "                # 6. Save the predictions\n",
    "                predictions.append(predicted_rating)\n",
    "\n",
    "    # 7. Apply MAE function on these two lists\n",
    "    mae = mean_absolute_error(predictions, actual)\n",
    "    return mae\n",
    "\n",
    "# Test the function with your user_ratings_train and user_ratings_test dataframes\n",
    "mae = compute_mae_using_cosine(user_ratings_train, user_ratings_test)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
