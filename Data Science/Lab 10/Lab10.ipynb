{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7mKEvgbYcZ"
   },
   "source": [
    "# Lab 10: Fully Connected Neural Networks\n",
    "\n",
    "In this assignment, we will learn fully connected neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwZwfFQYbYcc"
   },
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnoQz3MbYcd"
   },
   "source": [
    "This assignement should be run on Google Colab where you can use free GPU to accelerate the computation. Please refer to our slides to set up GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Rte_TebYce"
   },
   "source": [
    "### 1. Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1649559863527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "5YjZrt3dW4SB",
    "outputId": "3ff45b08-cc1c-4281-b8a8-f31d06275642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp39-cp39-win_amd64.whl (172.3 MB)\n",
      "     ------------------------------------- 172.3/172.3 MB 14.2 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 25.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rickw\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.0.0 torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqu1YdX2bYch"
   },
   "source": [
    "### 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1649559865200,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "KH1pKuAAXqzd",
    "outputId": "6987f9ee-b3ff-43c5-d4ea-4cd7d2a1ee5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqmII1sAbYcj"
   },
   "source": [
    "### 3. Mount to google drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17744,
     "status": "ok",
     "timestamp": 1649274810388,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "HdWuV25Qb-TM",
    "outputId": "09e93d6a-5e99-4510-e3be-eca9853e6566"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16380\\3890063786.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bAPbFl0bYck"
   },
   "source": [
    "### 4. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nVVA8yeXv9c"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTnQJNfyhmaE"
   },
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=100\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
    "args['log_interval']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1649276322480,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "4aMP_CHcX7jJ",
    "outputId": "7d252d46-624d-4416-9851-8cdff1ce97da"
   },
   "outputs": [],
   "source": [
    "# build an mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = F.relu(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = F.relu(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.fc3(h2) # output layer\n",
    "\n",
    "        return h3\n",
    "\n",
    "model = Net()\n",
    "model.cuda() # put the model on GPU\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U9yHGoTZi3e"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvuVjPqPabRC"
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YopP0oK5ca2u"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLn-uP_sct-a"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158181,
     "status": "ok",
     "timestamp": 1649276492527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "FgF4zxVlc28U",
    "outputId": "aaa6553d-5c92-4714-db39-37f12e88f997"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, args['epochs'] + 1):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OipUVawbYcr"
   },
   "source": [
    "## 2. Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA50s29XbYcs"
   },
   "source": [
    "### 1. Please use other activation functions, e.g., sigmoid, tanh, and then plot the training loss and testing accuracy. \n",
    "\n",
    "When plotting the training loss, the x-axis is iteration and the y-axis is training loss. When plotting the testing accuracy,  the x-axis is epoch and the y-axis is the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCUF04MYbYcs"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ThwUJxbYcs"
   },
   "source": [
    "### 2. Please use different layers in the model, e.g., 1 layer, 5 layers, 10 layers,  and then plot the training loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2fTAFyEbYcs"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
